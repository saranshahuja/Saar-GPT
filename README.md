# Saar-GPT
This is my Attempt at creating a very basic level of LLM using transformer models to achieve levels close to GPT-2 (124M parameters))>
